# UA Parking Intelligence Platform

A full-stack analytics platform for university parking survey analysis. Built with Next.js, FastAPI, and Supabase.

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.10+
- Supabase account (free tier works)

### Installation

```bash
# Clone the repo
git clone <your-repo-url>
cd ua-parking-platform

# Install frontend dependencies
npm install

# Install Python dependencies
pip install -r requirements.txt

# Copy environment template
cp .env.example .env.local
# Then fill in your values in .env.local
```

### Environment Variables

See `.env.example` for all required variables. You must set:
- `NEXT_PUBLIC_SUPABASE_URL` - Your Supabase project URL
- `NEXT_PUBLIC_SUPABASE_ANON_KEY` - Your Supabase anon key
- `GEMINI_API_KEY` - Google AI API key for embeddings

## ğŸ“Š Data Pipeline

### Step 1: Ingest and Clean Survey Data

```bash
# Place your Qualtrics export in data/raw/ (not tracked by git)
python scripts/load_qualtrics.py --input data/raw/survey.xlsx --output data/clean.csv
```

### Step 2: Build Metrics and Themes

```bash
python scripts/build_rollups.py --input data/clean.csv --output artifacts/
```

### Outputs
- `artifacts/metrics.json` - Aggregated statistics with n/N denominators
- `artifacts/themes.json` - Clustered themes with representative quotes
- `artifacts/rankings.json` - Weighted priority scores

## ğŸ§ª Smoke Test Checklist

```bash
# 1. Install dependencies
npm install
pip install -r requirements.txt

# 2. Run pipeline on sample data
python scripts/load_qualtrics.py --input data/raw/sample.xlsx --output data/clean.csv
python scripts/build_rollups.py --input data/clean.csv --output artifacts/

# 3. Start development server
npm run dev

# 4. Verify build works
npm run build
```

## ğŸ—ï¸ Project Structure

```
ua-parking-platform/
â”œâ”€â”€ app/                    # Next.js App Router pages
â”œâ”€â”€ components/             # React components
â”œâ”€â”€ lib/                    # Shared utilities
â”œâ”€â”€ scripts/                # Python pipeline scripts
â”‚   â”œâ”€â”€ load_qualtrics.py   # Ingestion + PII scrubbing
â”‚   â””â”€â”€ build_rollups.py    # Metrics and theme computation
â”œâ”€â”€ data/                   # Data files (gitignored except samples)
â”‚   â”œâ”€â”€ raw/                # Raw Qualtrics exports (gitignored)
â”‚   â””â”€â”€ clean.csv           # PII-scrubbed data (gitignored by default)
â”œâ”€â”€ artifacts/              # Pipeline outputs (JSON, tracked)
â”œâ”€â”€ docs/                   # Documentation
â”‚   â””â”€â”€ data_contract.md    # PII handling and schema docs
â”œâ”€â”€ config/                 # Centralized configuration
â””â”€â”€ public/                 # Static assets
```

## ğŸ“ Data Contract

See [docs/data_contract.md](docs/data_contract.md) for:
- Which columns are dropped (PII)
- Which columns are kept
- How quotes are anonymized

## ğŸ”’ Security Notes

- Raw survey files (XLSX) are **never** committed
- `clean.csv` is gitignored by default
- All quotes in `themes.json` are anonymized (no emails, names, or identifiers)
- `.env` files are gitignored; use `.env.example` as template

## ğŸ“¦ Dependencies

### Frontend (Node.js)
- Next.js 14 - React framework with App Router
- Tailwind CSS - Styling
- Recharts - Charting library
- @supabase/supabase-js - Database client

### Backend (Python)
- pandas - Data manipulation
- numpy - Numerical operations
- scikit-learn - Clustering
- google-generativeai - Gemini embeddings
- openpyxl - Excel file reading

## ğŸ“„ License

MIT
